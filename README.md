#  MMEE â€” Multimodal Embedding Explorer

The **Multimodal Embedding Explorer (MMEE)** is an interactive visualization and analysis tool built with **Streamlit** and **FastAPI** for exploring **joint image-text embeddings** derived from CLIP and similar models. It helps researchers, data scientists, and developers analyze alignment, detect outliers, and evaluate dataset authenticity in multimodal datasets.

---

##  Key Features

* **Image & Text Embedding Projection:**
  Visualize embeddings using **PCA**, **t-SNE**, and **UMAP** for both image and text data.

* **Joint Alignment & Similarity:**
  Align embeddings via **Orthogonal Procrustes** and analyze cosine similarity between image-text pairs.

* **Outlier Detection (Per-Class):**
  Detect anomalies in embeddings using methods like **Isolation Forest**, **LOF**, **kNN Quantile**, and **DBSCAN**.

* **Fusion Scorer:**
  Combine multiple features (cosine similarity, residuals, caption length, etc.) into a single prediction using **Logistic Regression with CV**.

* **Evaluation Dashboard:**
  Interactive confusion matrices, ROC/PR curves, and ranked tables comparing predictions vs ground truth.

* **Joint 2D Visualization:**
  Integrated image-text plots with connection lines showing embedding alignment.

---

## Project Overview

* **Goal:** Provide a fast, GPU-optimized, and intuitive interface for visualizing and diagnosing multimodal embeddings.
* **Use Cases:**

  * Inspect CLIP embedding quality
  * Detect mislabeled or noisy captions
  * Explore cross-modal alignment (image â†” text)
  * Compare outlier detection strategies

---

## ğŸ—‚ï¸ Repository Structure

```
â”œâ”€â”€ .devcontainer/                # VSCode remote dev setup
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ .gitignore                    # Standard Git ignore file
â”œâ”€â”€ DOCUMENTATION.md              # Full technical documentation
â”œâ”€â”€ CONTRIBUTING.md               # Contribution guidelines
â”œâ”€â”€ app/                          # Streamlit app source
â”‚   â”œâ”€â”€ main.py                   # Entry point for the Streamlit UI
â”‚   â”œâ”€â”€ config/                   # Configuration management
â”‚   â”‚   â”œâ”€â”€ settings.py           # Environment and path configs
â”‚   â”œâ”€â”€ data_loaders/             # Input data parsing
â”‚   â”‚   â”œâ”€â”€ caption_loader.py     # Handles caption reading
â”‚   â”‚   â”œâ”€â”€ dataset_loader.py     # Discovers datasets under /data
â”‚   â”‚   â””â”€â”€ label_loader.py       # Reads and processes label JSONs
â”‚   â”œâ”€â”€ detection/                # Outlier detection logic
â”‚   â”‚   â”œâ”€â”€ evaluation.py         # Precision/recall, confusion metrics
â”‚   â”‚   â”œâ”€â”€ fusion_scorer.py      # Logistic regression fusion model
â”‚   â”‚   â””â”€â”€ outlier_detectors.py  # IF, LOF, kNN, DBSCAN implementations
â”‚   â”œâ”€â”€ embedding/                # Embedding computation & projections
â”‚   â”‚   â”œâ”€â”€ compute.py            # Image/Text embedding functions
â”‚   â”‚   â””â”€â”€ projection.py         # PCA, t-SNE, UMAP utilities
â”‚   â”œâ”€â”€ ui/                       # UI rendering components
â”‚   â”‚   â”œâ”€â”€ display.py            # Visualization layout
â”‚   â”‚   â””â”€â”€ sidebar.py            # Sidebar parameter controls
â”‚   â”œâ”€â”€ utils/                    # Shared utilities
â”‚   â”‚   â”œâ”€â”€ clip_utils.py         # Core CLIP embedding utilities
â”‚   â”‚   â”œâ”€â”€ helpers.py            # Misc. helper functions
â”‚   â”‚   â””â”€â”€ validation.py         # Input validation & sanity checks
â”‚   â””â”€â”€ visualization/            # Plotly-based charts
â”‚       â”œâ”€â”€ plotly_helpers.py     # Plotly configs & styling
â”‚       â””â”€â”€ trace_builders.py     # Custom traces (authenticity/outliers)
|
â”œâ”€â”€ cache/                        # Cached embeddings & projections
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ projections/
â”‚   â””â”€â”€ thumbs/
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ tools/                        # Utility scripts
â”‚   â”œâ”€â”€ add_bad_captions.py       # Injects noisy captions for testing
â”‚   â”œâ”€â”€ check_gt.py               # Ground-truth checker
â”‚   â””â”€â”€ eval_sweep.py             # Evaluation sweeps over models
â””â”€â”€ utils/                        # Shared cross-module utilities
    â”œâ”€â”€ prepare_coco.py           # Prepare COCO dataset
    â”œâ”€â”€ prepare_cub.py            # Prepare CUB dataset
    â”œâ”€â”€ prepare_groundcap.py      # Prepare GroundCap dataset
```

### â–¶ï¸ Entry Point

The application starts from:

```
streamlit run app/main.py
```

This launches the full interactive Streamlit UI.

---

## âš™ï¸ Installation & Setup

1. **Clone the repository:**

   ```bash
   git clone https://github.com/<your-username>/mmee.git
   cd mmee
   ```

2. **Create a virtual environment (optional but recommended):**

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   .venv\Scripts\activate     # Windows
   ```

3. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

4. **Run the app:**

   ```bash
   streamlit run app/main.py
   ```

5. **Access the app:**
   Open the displayed local URL (typically `http://localhost:8501`).

---

##  Usage Overview

* **Dataset Selection:** Choose any dataset from the sidebar (expects `images/`, `captions.json`, and `labels.json`).
* **Embedding Computation:** Click buttons to compute image/text embeddings.
* **Projection Settings:** Pick PCA, t-SNE, or UMAP; tune parameters.
* **Outlier Detection:** Run Isolation Forest, LOF, or kNN to find anomalies.
* **Evaluation:** View confusion matrix, precision-recall stats, and sanity tables.
* **Visualization:** Inspect alignment in Image/Text/Joint embedding plots.

---

##  Technologies Used

* **Frontend:** Streamlit + Plotly
* **ML Libraries:** scikit-learn, UMAP-learn, NumPy, Pandas
* **Model:** CLIP (OpenAI / LAION variants)

---

## ğŸ“ Data Format

Each dataset folder under `data/` should contain:

```
images/               # All image files
captions.json         # {"img_1.jpg": ["caption1", "caption2", ...], ...}
labels.json           # {"img_1.jpg": {"class_name": "cat", "class_id": 1}, ...}
```

---

## ğŸ’¡ Tips

* Use **UMAP** for preserving local structure and neighborhood relations.
* Use **Isolation Forest** for general-purpose outlier detection.
* For noisy datasets, generate test files via `tools/add_bad_captions.py`.


---

## ğŸ§‘â€ğŸ’» Contributors

* **Aarya Pandey** â€” Project Developer
* **Mentors:** Laurens Hogeweg, Rajesh Gangireddy & Samet Akcay â€” Intel OpenVINO Toolkit (GSoC 2025)

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the LICENSE file for details.

---

**MMEE â€” Visualize, Compare, and Understand Multimodal Embeddings.**
